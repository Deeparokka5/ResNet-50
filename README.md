# ResNet-50
ResNet50: ResNet, short for Residual Networks is a classic neural network used as a backbone for many computer vision tasks.This model was the winner of ImageNet challenge in 2015.ResNet50 is a variant of ResNet model which has 48.Convolution layers along with 1 MaxPool and 1 Average Pool layer.In 2012 at the LSVRC2012 classification contest AlexNet won the the first price, After that ResNet was the most interesting thing that happened to the computer vision and the deep learning world.

Why ResNet?
The architecture ResNets provided makes it feasible to train extremely deep neural networks, which means that a network can have hundreds or thousands of layers and still function well.However, just adding layers on top of one another does not increase network depth. Due to the well-known vanishing gradient problem, which occurs when gradients are repeatedly multiplied as they are back-propagated to prior layers, deep networks can be challenging to train. As a result, the network's performance becomes saturated or even starts to decline quickly as it penetrates further.

Skip Connection â€” The Strength of ResNet ResNet first introduced the concept of skip connection. The main innovation of ResNet is the skip connection. As you know, without adjustments, deep networks often suffer from vanishing gradients, ie: as the model backpropagates, the gradient gets smaller and smaller. Tiny gradients can make learning intractable. It allows the network to learn the identity function, which allows it pass the the input through the block without passing through the other weight layers
